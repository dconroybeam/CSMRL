---
title: "CSMRL Model Analysis Script 20221024"
author: "Dan Conroy-Beam"
date: "2022-10-24"
output: html_document
---


######Packages######

```{r}
library(ggplot2)
library(gridExtra)
library(reshape2)
library(plyr)
library(grid)
library(gtable)
library(Rmisc)
library(ggpubr)

```



######Load Data######

```{r}
#Load in the data
data<-read.csv("Model Outputs/Simulation Accuracy/CSMRL Simulation Accuracy Results.csv")

data<-data[-1,]

data$modelLoop<-1:nrow(data)

#Melt the data
data<-melt(data,id.vars=c("dt","modelLoop","model","n"))

#Rename the files
colnames(data)[c(3,5:6)]<-c("trueModel","model","accuracy")

#Sort the data
data<-data[order(data$trueModel,data$model,data$n,data$modelLoop),]


#Create a list of all models and all sample sizes
#Will be handy in a moment
models<-unique(data$trueModel)
sizes<-sort(unique(data$n))

#Save figures?
sf<-1
```






######Mean Accuracy######

```{r}

###"Confusion Matrix"###
#Proportion of time that each model was the best model at all sample sizes and across true models

#Create a new dataframe to store all data
accData<-data.frame("modelLoop"=min(data$modelLoop):max(data$modelLoop))

#Store the sample size
accData$n<-sapply(accData$modelLoop,function(x) data$n[data$modelLoop==x][1])

#Store the true model for each model run
accData$trueModel<-sapply(accData$modelLoop,
                          function(x) 
                            data$trueModel[data$modelLoop==x][1])

#Determine whether each model was actually the best model in each model run
accData$nl<-sapply(min(accData$modelLoop):max(accData$modelLoop),
                   simplify=T,
                   function(x) 
  data$accuracy[data$modelLoop==x][1]==
    max(data$accuracy[data$modelLoop==x]))

accData$tRecip<-sapply(min(accData$modelLoop):max(accData$modelLoop),
                       simplify=T,
                       function(x)
  data$accuracy[data$modelLoop==x][2]==
    max(data$accuracy[data$modelLoop==x]))


#Break ties
#Tied models share points: .5 if two models tie, .33 if three, etc.
accData[,4:5]<-t(apply(accData[,4:5],1,function(x) x*(1/sum(as.numeric(x)))))

#A blank dataframe to store the actual confusion matrix
confusion<-data.frame("n"=rep(sizes,each=length(models)),
                      "trueModel"=rep(models,
                                      times=length(sizes)))

#Store the total proportion of times in which each model was the best across sample sizes and true models
confusion$nl<-as.numeric(tapply(accData$nl,
                                list(accData$trueModel,
                                     accData$n),
                                mean))
confusion$tRecip<-as.numeric(tapply(accData$tRecip,
                                    list(accData$trueModel,
                                         accData$n),
                                    mean))

#Melt the dataframe for easier plotting/analysis
confusion<-melt(confusion,
                id.vars=c("n","trueModel"),
                measure.vars=models)

#Rename dataframes
colnames(confusion)<-c("n","trueModel","model","p")

#Relabel factor levels
confusion$trueModel<-factor(confusion$trueModel,
                            levels=c("nl","tRecip"),
                            labels=c("No Learning","RWTS"))

confusion$model<-factor(confusion$model,
                        levels=c("nl","tRecip"),
                        labels=c("No Learning","RWTS"))


#Plotting all confusion matrices (and storing them in lists)
confusionPlots<-lapply(sizes,function(x) qplot(model,
                                               trueModel,
                                               fill=p,
                                               data=confusion[confusion$n==x,],
                                               xlab="Best Model",
                                               ylab="True Model")+
                         geom_tile(color="white")+
                         geom_text(label=round(confusion$p[confusion$n==x],2),
                                   size=I(6))+
                         scale_fill_gradient(low="white",high="red")+
                         theme_bw(base_size=20)+
                         theme(legend.position="none",
                               panel.grid.major = element_blank(), 
                               panel.grid.minor = element_blank())+
                         scale_y_discrete(limits=
                                            rev(levels(confusion$trueModel))))


if(sf==1){
  sapply(1:length(sizes),function(x)
    ggsave(paste0("Figures/","CSMRL Confusion Matrix N",sizes[x],".tiff"),
           confusionPlots[[x]],
           width=10,height=10,
           units="in",dpi=300)
    )
}

```


###Average Accuracy Plots###

```{r}

#Create a single dataframe to store all plotting data
plotData<-data.frame("n"=rep(sizes,times=length(models)*length(models)),
                     "trueModel"=rep(models,
                                     each=length(unique(data$n))*length(models)),
                     "model"=rep(models,each=length(sizes),times=length(models)),
                     "accuracy"=0,"lci"=0,"uci"=0)

#Horrible, ugly line
#Loops through true models, and then through tested models, and calculates the average accuracy as a function of sample size
plotData$accuracy<-as.vector(
  sapply(1:length(models),
         function(y)
           as.vector(sapply(1:length(models),
                            function(x)
                              tapply(data$accuracy[data$trueModel==models[y] & 
                                                     data$model==models[x]],
                                     data$n[data$trueModel==models[y]
                                            & data$model==models[x]],
                                     mean)))))

#Relabel factor levels
plotData$trueModel<-factor(plotData$trueModel,
                            levels=c("nl","tRecip"),
                            labels=c("No Learning","RWTS"))

plotData$model<-factor(plotData$model,
                            levels=c("nl","tRecip"),
                            labels=c("No Learning","RWTS"))


#Another horrible, ugly line
#Does the same thing as above, but calculates confidence interval width
cis<-as.vector(
  sapply(1:length(models),
         function(y) 
           as.vector(sapply(1:length(models),
                            function(x)
                              tapply(data$accuracy[data$trueModel==models[y] & 
                                                     data$model==models[x]],
                                     data$n[data$trueModel==models[y] & 
                                              data$model==models[x]],
                                     function(z) sd(z)*1.96)))))
cis<-cis/sqrt(plotData$n)

#Compute the lower and upper bounds of the confidence interval
plotData$lci<-plotData$accuracy-cis
plotData$uci<-plotData$accuracy+cis

#Set the boundaries of this to 0 and 1
plotData$lci[plotData$lci<0]<-0
plotData$uci[plotData$uci>1]<-1

plotData[,4:6]<-plotData[,4:6]*100


###Mean Acccuracy Plot###

accPlot<-qplot(trueModel,accuracy,fill=model,
               data=plotData,geom="blank",
               xlab="True Model",
        ylab="Couple Simulation Accuracy\n(% Observed Couples Reproduced)")+
    geom_bar(stat="identity",position="dodge")+
    geom_errorbar(aes(ymin=lci,
                      ymax=uci),
                  position="dodge")+
    theme_classic(base_size=20)+
    scale_fill_discrete(name="Tested Model")+
    theme(legend.position="top")+coord_cartesian(ylim=c(0,100))



if(sf==1){
  
  ggsave("Figures/CSMRL Accuracy Plot.tiff",accPlot,
         width=12,height=6,units="in",dpi=300)
  
}

````
